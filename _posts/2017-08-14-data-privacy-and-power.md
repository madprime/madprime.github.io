---
layout: post-fellow
title:  'Data, Privacy, and Power'
date:   2017-08-14 9:07:00 +0700
---
It is 2017 and the four largest companies in the world, by market cap, are
digital. Apple, Alphabet (Google), Microsoft, and Amazon.

Our era is defined by increasingly pervasive personal data. Largely invisible
to us, information about us is aggregated, cross-referenced, and applied in
ways that define an increasing swath of our lives. It has value, it is bought,
and it is sold. We are troubled. Amidst our discomfort, "privacy" becomes a
rallying cry.

I think this word – "privacy" – has more emotive content than clarity.

I find myself increasingly unhappy with "privacy" used to frame our big data
problems. It seems to be a phenomenon that changes rapidly, from generation to
generation. Increased housing gave humanity more space to separate, but social
networks introduced unending updates.

The word "privacy" invites us to imagine consequences on a personal scale. Of
parents uncovering romantic activity they would oppose, or an employer learning
of an employee's mental health issues.

Personal secrets revealed to those that know us.

![photo of a woman hiding her face with her hands]({{site.baseurl}}/images/abigail-keenan-27295-cropped-edited.jpg)
<small>_Photo by [Abigail Keenan](https://unsplash.com/@akeenster) on Unsplash_</small>

But those that hold our data are largely faceless. Do we feel the same loss of
"privacy", if the other is a stranger?

It becomes facile to draw on the word "privacy" to forward argument. When
health data is breached, it is framed as a "privacy breach" – and the gravity
of it is emphasized to us by the high value these records have in black
markets. But what do the individuals in this data experience as a result? Is it
anything like the personal privacy breaches I just described? These records
have value because they are used for fraud. The consequence for individuals is
unclear. Perhaps it is "identity theft". Is "identity theft" a "privacy" issue?
To me, the word seems stretched.

I think there is an older concept and more accurate word than "privacy" to
describe our discomfort: Power.

Our data holds power. Who has it? How can they use it? How will they use it?
Are there accidents of power, and unintended consequences?

![photo of metal chains]({{site.baseurl}}/images/bernard-spragg-chains-cropped-edited.jpg)
<small>_Photo by [Bernard Spragg](https://www.flickr.com/photos/volvob12b/9519486593/) on Flickr_</small>

It is 2017 and the four largest companies in the world, by market cap, are
digital. Our lives are defined by their products. We are entangled, enmeshed,
and entrapped. Our personal data is integral to the experiences they give us.
It is used to optimize, to personalize, to bring us more quickly to the
solutions we need. It gives us unprecedented convenience. It is a powerful
tool.

This power can turn in less benign directions. The algorithms that automate
tasks may go awry. Without supervision, we fear unintended side-effects and
algorithmic discrimination. Data can also be used more deliberately, more
coldly, to steer our spending and personalize the prices of products we seek
to purchase.

We seek to regain control. And so we call for data "ownership".

![photo of raised fist]({{site.baseurl}}/images/pabak-sarkar-fist-cropped-edited.jpg)
<small>_Photo by [Pabak Sarkar](https://www.flickr.com/photos/pabak/14496866427/) on Flickr (CC BY 2.0)_</small>

"Ownership" is another word which has more emotional power than clarity. Using
language developed in reference to physical objects invites us to fallacious
reasoning. It tempts us to imagine data as a singular object that can be moved
or destroyed. But it is trivially copied, refracted and recombined.

We should set aside these words, and speak of power. For our data, we seek two
complementary things: we seek to control what others do, and we seek to empower
ourselves.

Control is likely to require regulation. If and when we take legal actions, I
hope these are guided not by fear, but by understanding. Reflexive regulation
to prevent imagined consequences can cause more harm than good. But if we can
quantify the costs and benefits of control then we become justified in action.

My own work explores empowering ourselves. I'm unclear what value it will have!
Our ability to aggregate our own data – and use it – is yet to be explored. But
I hope, in [Open Humans](https://www.openhumans.org/), we more fully access the
potential of our personal data, and discover a new power for ourselves.

<hr>

<small>_Thanks to Andrew Rens, Achal Prabhala, Steve Song, Bastian Greshake
Tzovaras, and Astra Taylor for related discussion._</small>
